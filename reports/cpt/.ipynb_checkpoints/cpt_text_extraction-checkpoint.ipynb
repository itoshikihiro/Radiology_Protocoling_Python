{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation,strip_numeric,remove_stopwords, stem_text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_char(txt):\n",
    "    return re.sub(r'[^a-zA-Z0-9 :,_/;.]',r'',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(df_filter, filter_name):\n",
    "    return_val = df_filter.copy()\n",
    "    return_val = return_val.fillna('N/A')\n",
    "    return_val = return_val[return_val[filter_name]!='N/A']\n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unreadable(txt):\n",
    "    return re.sub(r'_[a-zA-Z0-9]+_',r'\\n',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_str(txt):\n",
    "    return_val = txt.replace('\\r',' ')\n",
    "    return_val = return_val.strip()\n",
    "    return_val = re.sub(r'(\\s*\\n\\s*){2,}',r';', return_val)\n",
    "    return_val = return_val.replace('(\\n)+',' ')\n",
    "    return_val = re.sub(r'(\\s)+',r' ', return_val)\n",
    "    return_val = return_val.strip()\n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_radi_txt(df_filter, filter_str):\n",
    "    return_val = df_filter.copy()\n",
    "    # remove empty entries\n",
    "    return_val = remove_empty(return_val, filter_str)\n",
    "    # remove unreadable str\n",
    "    # remove speical char\n",
    "    return_val[filter_str] =  return_val[filter_str].apply(remove_unreadable)\n",
    "    # remove empty entries\n",
    "    return_val = remove_empty(return_val, filter_str)\n",
    "    # format_str\n",
    "    return_val[filter_str] =  return_val[filter_str].apply(format_str)\n",
    "    # remove empty entries\n",
    "    return_val = remove_empty(return_val, filter_str)\n",
    "    # format_str\n",
    "    return_val[filter_str] =  return_val[filter_str].apply(remove_special_char)\n",
    "    # remove empty entries\n",
    "    return_val = remove_empty(return_val, filter_str)\n",
    "    \n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_fr_path(file_path):\n",
    "    df_filter = pd.read_excel(file_path)\n",
    "    # filter all data without any empty data\n",
    "    df_filter = preprocess_radi_txt(df_filter, 'Radiology text')\n",
    "    return df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation,remove_stopwords, stem_text]\n",
    "    words = preprocessing.preprocess_string(txt.lower(), CUSTOM_FILTERS)\n",
    "    if not words:\n",
    "        return 'N/A'\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpt_ext(txt):\n",
    "    try:\n",
    "        splited_list = txt.split(';')\n",
    "        new_txt = \"\"\n",
    "        for i in splited_list:\n",
    "            for j in i.split(':'):\n",
    "                if j.strip().lower()=='procedure':\n",
    "                    new_txt=i.split(':')[1].strip()\n",
    "                    return new_txt\n",
    "                elif j.strip().lower()=='exam':\n",
    "                    new_txt=i.split(':')[1].strip()\n",
    "                    return new_txt\n",
    "        for i in range(len(splited_list)):\n",
    "            tmp_txt = splited_list[i].strip()\n",
    "            if 'REPORT'== tmp_txt.split(\" \")[0].strip():\n",
    "                new_txt = tmp_txt.split(\" \")[1:]\n",
    "                new_txt = \" \".join(new_txt).strip()\n",
    "                if new_txt == \"\":\n",
    "                    new_txt = splited_list[i+1].strip()\n",
    "        return new_txt\n",
    "    except:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning for CPT\n",
    "def df_clean_CPT(df_filter):\n",
    "    df_return = df_filter.copy()\n",
    "    # specific cleaning empty entry in CPT_text\n",
    "    # empty entries mean failed convertion during the extraction process\n",
    "    df_return['CPT_text'] = df_return['Radiology text'].apply(cpt_ext)\n",
    "    df_return = remove_empty(df_return, 'CPT_text')\n",
    "    # transferring words to sentences\n",
    "    df_return['CPT_text'] = df_return['CPT_text'].apply(clean_txt)\n",
    "    df_return = remove_empty(df_return, 'CPT_text')\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    # load data as dataframe\n",
    "    df_filter = read_df_fr_path(filepath)\n",
    "    # filter all data without any empty data\n",
    "    df_return = df_clean_CPT(df_filter)\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel('../../data/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiology_text = preprocess_radi_txt(data_df, 'Radiology text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiology_text['CPT_text'] = radiology_text['Radiology text'].apply(cpt_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring words to sentences\n",
    "radiology_text['CPT_text'] = radiology_text['CPT_text'].apply(clean_txt)\n",
    "radiology_text = remove_empty(radiology_text, 'CPT_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiology_text = remove_empty(radiology_text, 'CPT_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = {'radiology_text':radiology_text['Radiology text'], 'cpt_ext':radiology_text['CPT_text']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"/Users/hiro/Desktop/renew_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['2atoha', 's1so9', 'lkoc', 'proin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n",
      "2atoha\n",
      "s1so9\n",
      "lkoc\n",
      "proin\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    word_val = word\n",
    "    word_val = re.sub(r'(\\d+[a-zA-Z]*)',r' ', word_val)\n",
    "    word_val = re.sub(r'([a-zA-Z]*\\d+[a-zA-Z]*)',r' ', word_val)\n",
    "    word_val = re.sub(r'([a-zA-Z]*\\d+)',r' ', word_val)\n",
    "    if word_val ==' ':\n",
    "        print(\"empty\")\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data('../../data/train.xlsx')\n",
    "test_df = load_data('../../data/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_features=400)\n",
    "tfidf = TfidfTransformer()\n",
    "def X_vectorization(df):\n",
    "    return_df = vect.fit_transform(df)\n",
    "    return_df = tfidf.fit_transform(return_df)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_vectorization(train_df['CPT_text'])\n",
    "y_train = train_df['cpt_label']\n",
    "X_test = X_vectorization(test_df['CPT_text'])\n",
    "y_test = test_df['cpt_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg():\n",
    "    print(\" \")\n",
    "    print(\"logistic regression\")\n",
    "    reg = LogisticRegression(random_state=0, solver = 'newton-cg', class_weight='balanced')\n",
    "    reg = reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_for():\n",
    "    print(\" \")\n",
    "    print(\"random forest\")\n",
    "    reg = RandomForestClassifier(\n",
    "        random_state=0, \n",
    "        class_weight = 'balanced',\n",
    "        n_jobs=-1)\n",
    "    reg = reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_test():\n",
    "    print(\" \")\n",
    "    print(\"xgboost\")\n",
    "    reg = XGBClassifier(n_estimators=100, \n",
    "                        max_depth=3, \n",
    "                        random_state=0,\n",
    "                        n_jobs = -1)\n",
    "    reg = reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    print (classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg()\n",
    "ran_for()\n",
    "xgboost_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
