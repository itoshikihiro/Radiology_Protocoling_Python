{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation,strip_numeric,remove_stopwords, stem_text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import gensim\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_str(txt):\n",
    "    return_val = txt.lower().replace('\\r',' ')\n",
    "    return_val = return_val.replace('\\n',' ')\n",
    "    return_val = return_val.lower()\n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_fr_path(file_path):\n",
    "    df_filter = pd.read_excel(file_path)\n",
    "    # filter all data without any empty data\n",
    "    df_filter = df_filter.fillna('N/A')\n",
    "    df_filter = df_filter[df_filter['Radiology text']!='N/A']\n",
    "    df_filter['Radiology text'] = df_filter['Radiology text'].apply(format_str)\n",
    "    \n",
    "    return df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd_impression_ext(txt):\n",
    "    try:\n",
    "        splited_list = txt.split('impression:')\n",
    "        new_txt = splited_list[1]\n",
    "        return new_txt.strip()\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd_ci_ext(txt):\n",
    "    try:\n",
    "        splited_list = txt.lower().split('clinical indication:')\n",
    "        new_txt = splited_list[1]\n",
    "        new_txt = new_txt.split(':')[0].split(\" \")[:-1]\n",
    "        return \" \".join(new_txt).strip()\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_to_icd(ser_1, ser_2):\n",
    "    new_ser = ser_1+\" \"+ser_2\n",
    "    return new_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation,remove_stopwords, stem_text]\n",
    "    words = preprocessing.preprocess_string(txt.lower(), CUSTOM_FILTERS)\n",
    "    if not words:\n",
    "        return 'N/A'\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning for CPT\n",
    "def df_clean_ICD(df_filter):\n",
    "    df_return = df_filter.copy()\n",
    "    # specific cleaning empty entry in CPT_text\n",
    "    # empty entries mean failed convertion during the extraction process\n",
    "    df_return['icd_impre_txt'] = df_return['Radiology text'].apply(icd_impression_ext)\n",
    "    df_return['icd_ci_txt'] = df_return['Radiology text'].apply(icd_ci_ext)\n",
    "    df_return['ICD_text'] = merge_to_icd(df_return['icd_impre_txt'],df_return['icd_ci_txt'])\n",
    "    df_return = df_return[df_return['ICD_text']!=' ']\n",
    "    # transferring words to sentences\n",
    "    df_return['ICD_text'] = df_return['ICD_text'].apply(clean_txt)\n",
    "    df_return = df_return[df_return['ICD_text']!='N/A']\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_10_all = {}\n",
    "for l in ascii_uppercase:\n",
    "    for i in range(0,10):\n",
    "        for j in range(0,10):\n",
    "            new_str = l+str(i)+str(j)\n",
    "            if (l=='A') or (l=='B'):\n",
    "                icd_10_all.update({new_str:'A00-B99'})\n",
    "            elif (l=='C'):\n",
    "                icd_10_all.update({new_str:'C00-D49'})\n",
    "                if (i==4) and (j==4):\n",
    "                    icd_10_all.update({'C4A':'C00-D49'})\n",
    "                if (i==7) and (j==7):\n",
    "                    icd_10_all.update({'C7A':'C00-D49'})\n",
    "                    icd_10_all.update({'C7B':'C00-D49'})\n",
    "            elif (l=='D'):\n",
    "                if (i<=4):\n",
    "                    icd_10_all.update({new_str:'C00-D49'})\n",
    "                else:\n",
    "                    icd_10_all.update({new_str:'D50-D89'})\n",
    "                if (i==9) and (j==9):\n",
    "                    icd_10_all.update({'D3A':'C00-D49'})\n",
    "            elif (l=='E'):\n",
    "                icd_10_all.update({new_str:'E00-E89'})\n",
    "            elif (l=='F'):\n",
    "                icd_10_all.update({new_str:'F01-F99'})\n",
    "            elif (l=='G'):\n",
    "                icd_10_all.update({new_str:'G00-G99'})\n",
    "            elif (l=='H'):\n",
    "                if (i<=5):\n",
    "                    icd_10_all.update({new_str:'H00-H59'})\n",
    "                else:\n",
    "                    icd_10_all.update({new_str:'H60-H95'})\n",
    "            elif (l=='I'):\n",
    "                icd_10_all.update({new_str:'I00-I99'})\n",
    "            elif (l=='J'):\n",
    "                icd_10_all.update({new_str:'J00-J99'})\n",
    "            elif (l=='K'):\n",
    "                icd_10_all.update({new_str:'K00-K95'})\n",
    "            elif (l=='L'):\n",
    "                icd_10_all.update({new_str:'L00-L99'})\n",
    "            elif (l=='M'):\n",
    "                icd_10_all.update({new_str:'M00-M99'})\n",
    "                if (i==1) and (j==4):\n",
    "                    icd_10_all.update({'M1A':'M00-M99'})\n",
    "            elif (l=='N'):\n",
    "                icd_10_all.update({new_str:'N00-N99'})\n",
    "            elif (l=='O'):\n",
    "                icd_10_all.update({new_str:'O00-O9A'})\n",
    "                if (i==9) and (j==9):\n",
    "                    icd_10_all.update({'O9A':'O00-O9A'})\n",
    "            elif (l=='P'):\n",
    "                icd_10_all.update({new_str:'P00-P96'})\n",
    "            elif (l=='Q'):\n",
    "                icd_10_all.update({new_str:'Q00-Q99'})\n",
    "            elif (l=='R'):\n",
    "                icd_10_all.update({new_str:'R00-R99'})\n",
    "            elif (l=='S') or (l=='T'):\n",
    "                icd_10_all.update({new_str:'S00-T88'})\n",
    "            elif (l=='V') or (l=='W') or (l=='X') or (l=='Y'):\n",
    "                icd_10_all.update({new_str:'V00-Y99'})\n",
    "            elif (l=='Z'):\n",
    "                icd_10_all.update({new_str:'Z00-Z99'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    # load data as dataframe\n",
    "    df_filter = read_df_fr_path(filepath)\n",
    "    # filter all data without any empty data\n",
    "    df_return = df_clean_ICD(df_filter)\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(df):\n",
    "    general_icd_label = []\n",
    "    for i in df['icd_label']:\n",
    "        splitted_list = i.split('.')\n",
    "        code = splitted_list[0]\n",
    "        x = icd_10_all.get(splitted_list[0])\n",
    "        general_icd_label.append(x)\n",
    "    return general_icd_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(\"../../data/train.xlsx\")\n",
    "test_df = load_data(\"../../data/test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['general_icd_label'] = load_label(train_df)\n",
    "test_df['general_icd_label'] = load_label(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['ICD_text']\n",
    "y_train = train_df['general_icd_label']\n",
    "X_test = test_df['ICD_text']\n",
    "y_test = test_df['general_icd_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_features=400)\n",
    "tfidf = TfidfTransformer()\n",
    "def X_vectorization(df):\n",
    "    return_df = vect.fit_transform(df)\n",
    "    return_df = tfidf.fit_transform(return_df)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_vectorization(X_train)\n",
    "X_test = X_vectorization(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg():\n",
    "    print(\" \")\n",
    "    print(\"logistic regression\")\n",
    "    reg = LogisticRegression(random_state=0, solver = 'newton-cg', class_weight='balanced')\n",
    "    reg = reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    print (classification_report(y_test, pred, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "def ran_for():\n",
    "    print(\" \")\n",
    "    print(\"random forest\")\n",
    "    reg = RandomForestClassifier(\n",
    "        random_state=0, \n",
    "        class_weight = 'balanced',\n",
    "        n_jobs=-1)\n",
    "    reg = reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    print (classification_report(y_test, pred, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "def xgboost_test():\n",
    "    print(\" \")\n",
    "    print(\"xgboost\")\n",
    "    reg = XGBClassifier(n_estimators=100, \n",
    "                        max_depth=3, \n",
    "                        random_state=0,\n",
    "                        n_jobs = -1)\n",
    "    reg = reg.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    print (classification_report(y_test, pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg()\n",
    "ran_for()\n",
    "xgboost_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
